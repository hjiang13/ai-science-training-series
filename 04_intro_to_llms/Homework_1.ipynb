{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjiang13/ai-science-training-series/blob/main/04_intro_to_llms/Homework_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aP-OmdvVoj"
      },
      "source": [
        "### Let's write an elementary tokenizer that uses words as tokens.\n",
        "\n",
        "We will use Mark Twain's _Life On The Mississippi_ as a test bed. The text is in the accompanying file 'Life_On_The_Mississippi.txt'\n",
        "\n",
        "Here's a not-terribly-good such tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/hjiang13/ai-science-training-series/blob/main/04_intro_to_llms/Life_On_The_Mississippi.txt\""
      ],
      "metadata": {
        "id": "pdrTwS9gxM_K",
        "outputId": "81fdcfcf-4258-40e3-8566-0b8cf7a9e7d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-13 03:11:16--  https://github.com/hjiang13/ai-science-training-series/blob/main/04_intro_to_llms/Life_On_The_Mississippi.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 939898 (918K) [text/plain]\n",
            "Saving to: ‘Life_On_The_Mississippi.txt’\n",
            "\n",
            "Life_On_The_Mississ 100%[===================>] 917.87K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-03-13 03:11:17 (11.9 MB/s) - ‘Life_On_The_Mississippi.txt’ saved [939898/939898]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PIVKHC8gvVol",
        "outputId": "09c64f14-87be-4fc7-9c01-92bf3a27392a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"04_intro_to_llms\":{\"items\":[{\"name\":\"Figures\",\"path\":\"04_intro_to_llms/Figures\",\"contentType\":\"directory\"},{\"name\":\"Homework_1.ipynb\",\"path\":\"04_intro_to_llms/Homework_1.ipynb\",\"contentType\":\"file\"},{\"name\":\"Life_On_The_Mississippi.txt\",\"path\":\"04_intro_to_llms/Life_On_The_Mississippi.txt\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"04_intro_to_llms/README.md\",\"contentType\":\"file\"},{\"name\":\"Sequential_Data_Models.ipynb\",\"path\":\"04_intro_to_llms/Sequential_Data_Models.ipynb\",\"contentType\":\"file\"}],\"totalCount\":5},\"\":{\"items\":[{\"name\":\"00_introToAlcf\",\"path\":\"00_introToAlcf\",\"contentType\":\"directory\"},{\"name\":\"01_intro_AI_on_Supercomputer\",\"path\":\"01_intro_AI_on_Supercomputer\",\"contentType\":\"directory\"},{\"name\":\"02_intro_neural_networks\",\"path\":\"02_intro_neural_networks\",\"contentType\":\"directory\"},{\"name\":\"03_advanced_neural_networks\",\"path\":\"03_advanced_neural_networks\",\"contentType\":\"directory\"},{\"name\":\"04_intro_to_llms\",\"path\":\"04_intro_to_llms\",\"contentType\":\"directory\"},{\"name\":\"05_llm_part2\",\"path\":\"05_llm_part2\",\"contentType\":\"directory\"},{\"name\":\"06_parallel_training\",\"path\":\"06_parallel_training\",\"contentType\":\"directory\"},{\"name\":\"08_advanced_architectures_methods\",\"path\":\"08_advanced_architectures_methods\",\"contentType\":\"directory\"},{\"name\":\"bonusMaterial\",\"path\":\"bonusMaterial\",\"contentType\":\"directory\"},{\"name\":\".gitattributes\",\"path\":\".gitattributes\",\"contentType\":\"file\"},{\"name\":\".gitconfig\",\"path\":\".gitconfig\",\"contentType\":\"file\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"}],\"totalCount\":13}},\"fileTreeProcessingTime\":4.977568,\"foldersToFetch\":[],\"repo\":{\"id\":754304606,\"defaultBranch\":\"main\",\"name\":\"ai-science-training-series\",\"ownerLogin\":\"hjiang13\",\"currentUserCanPush\":false,\"isFork\":true,\"isEmpty\":false,\"createdAt\":\"2024-02-07T19:41:43.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/43047519?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":false},\"symbolsExpanded\":false,\"treeExpanded\":true,\"refInfo\":{\"name\":\"main\",\"listCacheKey\":\"v0:1707334909.286934\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"063b58e131dad402e1dbff364ff940432b72468a\"},\"path\":\"04_intro_to_llms/Life_On_The_Mississippi.txt\",\"currentUser\":null,\"blob\":{\"rawLines\":[\"\\ufeffThe', 1)\n",
            "('Project', 60)\n",
            "('Gutenberg', 17)\n",
            "('eBook', 4)\n",
            "('of', 3943)\n",
            "('Life', 4)\n",
            "('on', 759)\n",
            "('the', 7264)\n",
            "('Mississippi\\\\r\",\"', 1)\n",
            "('\\\\r\",\"This', 1)\n",
            "('ebook', 2)\n",
            "('is', 949)\n",
            "('for', 882)\n",
            "('use', 33)\n",
            "('anyone', 3)\n",
            "('anywhere', 6)\n",
            "('in', 2087)\n",
            "('United', 30)\n",
            "('States', 24)\n",
            "('and\\\\r\",\"most', 2)\n",
            "('other', 179)\n",
            "('parts', 5)\n",
            "('world', 33)\n",
            "('at', 617)\n",
            "('no', 281)\n",
            "('cost', 17)\n",
            "('and', 4882)\n",
            "('with', 886)\n",
            "('almost', 31)\n",
            "('restrictions\\\\r\",\"whatsoever.', 1)\n",
            "('You', 84)\n",
            "('may', 73)\n",
            "('copy', 12)\n",
            "('it,', 171)\n",
            "('give', 60)\n",
            "('it', 1236)\n",
            "('away', 95)\n",
            "('or', 490)\n",
            "('re-use', 2)\n",
            "('under', 93)\n",
            "('terms\\\\r\",\"of', 1)\n",
            "('License', 7)\n",
            "('included', 2)\n",
            "('this', 523)\n",
            "('online\\\\r\",\"at', 1)\n",
            "('www.gutenberg.org.', 2)\n",
            "('If', 70)\n",
            "('you', 714)\n",
            "('are', 307)\n",
            "('not', 596)\n",
            "('located', 8)\n",
            "('States,\\\\r\",\"you', 1)\n",
            "('will', 244)\n",
            "('have', 486)\n",
            "('to', 3132)\n",
            "('check', 3)\n",
            "('laws', 12)\n",
            "('country', 44)\n",
            "('where', 123)\n",
            "('located\\\\r\",\"before', 1)\n",
            "('using', 10)\n",
            "('eBook.\\\\r\",\"\\\\r\",\"Title:', 1)\n",
            "('Mississippi\\\\r\",\"\\\\r\",\"\\\\r\",\"Author:', 1)\n",
            "('Mark', 2)\n",
            "('Twain\\\\r\",\"\\\\r\",\"Release', 1)\n",
            "('date:', 1)\n",
            "('July', 6)\n",
            "('10,', 1)\n",
            "('2004', 1)\n",
            "('[eBook', 1)\n",
            "('#245]\\\\r\",\"', 1)\n",
            "('Most', 2)\n",
            "('recently', 3)\n",
            "('updated:', 1)\n",
            "('January', 2)\n",
            "('1,', 2)\n",
            "('2021\\\\r\",\"\\\\r\",\"Language:', 1)\n",
            "('English\\\\r\",\"\\\\r\",\"Credits:', 1)\n",
            "('Produced', 1)\n",
            "('by', 555)\n",
            "('David', 2)\n",
            "('Widger.', 2)\n",
            "('Earliest', 2)\n",
            "('PG', 3)\n",
            "('text', 4)\n",
            "('edition', 3)\n",
            "('produced', 13)\n",
            "('Graham', 1)\n",
            "('Allan\\\\r\",\"\\\\r\",\"\\\\r\",\"***', 1)\n",
            "('START', 1)\n",
            "('OF', 16)\n",
            "('THE', 14)\n",
            "('PROJECT', 4)\n",
            "('GUTENBERG', 3)\n",
            "('EBOOK', 2)\n",
            "('LIFE', 2)\n",
            "('ON', 4)\n",
            "('MISSISSIPPI', 3)\n",
            "('***\\\\r\",\"\\\\r\",\"Produced', 1)\n",
            "('Graham\\\\r\",\"Allan\\\\r\",\"\\\\r\",\"\\\\r\",\"\\\\r\",\"\\\\r\",\"LIFE', 1)\n"
          ]
        }
      ],
      "source": [
        "wdict = {}\n",
        "with open('Life_On_The_Mississippi.txt', 'r') as L:\n",
        "    line = L.readline()\n",
        "    nlines = 1\n",
        "    while line:\n",
        "\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if wdict.get(word) is not None:\n",
        "                wdict[word] += 1\n",
        "            else:\n",
        "                wdict[word] = 1\n",
        "        line = L.readline()\n",
        "        nlines += 1\n",
        "\n",
        "nitem = 0 ; maxitems = 100\n",
        "for item in wdict.items():\n",
        "    nitem += 1\n",
        "    print(item)\n",
        "    if nitem == maxitems: break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rjp59elvVom"
      },
      "source": [
        "This is unsatisfactory for a few reasons:\n",
        "\n",
        "* There are non-ASCII (Unicode) characters that should be stripped (the so-called \"Byte-Order Mark\" or BOM \\ufeff at the beginning of the text);\n",
        "\n",
        "* There are punctuation marks, which we don't want to concern ourselves with;\n",
        "\n",
        "* The same word can appear capitalized, or lower-case, or with its initial letter upper-cased, whereas we want them all to be normalized to lower-case.\n",
        "\n",
        "Part 1 of this assignment: insert code in this loop to operate on the str variable 'line' so as to fix these problems before 'line' is split into words.\n",
        "\n",
        "A hint to one possible way to do this: use the 'punctuation' character definition in the Python 'string' module, the 'maketrans' and 'translate' methods of Python's str class, to eliminate punctuation, and the regular expression ('re') Python module to eliminate any Unicode---it is useful to know that the regular expression r'[^\\x00-x7f]' means \"any character not in the vanilla ASCII set.\n",
        "\n",
        "Part 2: Add code to sort the contents of wdict by word occurrence frequency.  What are the top 100 most frequent word tokens?  Adding up occurrence frequencies starting from the most frequent words, how many distinct words make up the top 90% of word occurrences in this \"corpus\"?\n",
        "\n",
        "For this part, the docs of Python's 'sorted' and of the helper 'itemgetter' from 'operator' reward study.\n",
        "\n",
        "Write your modified code in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string"
      ],
      "metadata": {
        "id": "tMFhCmd20cve"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "aFlbEN0qvVom",
        "outputId": "60fb9429-de1e-46ca-917e-ab3b13672957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('payloadallshortcutsenabledfalsefiletree04introtollmsitemsnamefigurespath04introtollmsfigurescontenttypedirectorynamehomework1ipynbpath04introtollmshomework1ipynbcontenttypefilenamelifeonthemississippitxtpath04introtollmslifeonthemississippitxtcontenttypefilenamereadmemdpath04introtollmsreadmemdcontenttypefilenamesequentialdatamodelsipynbpath04introtollmssequentialdatamodelsipynbcontenttypefiletotalcount5itemsname00introtoalcfpath00introtoalcfcontenttypedirectoryname01introaionsupercomputerpath01introaionsupercomputercontenttypedirectoryname02introneuralnetworkspath02introneuralnetworkscontenttypedirectoryname03advancedneuralnetworkspath03advancedneuralnetworkscontenttypedirectoryname04introtollmspath04introtollmscontenttypedirectoryname05llmpart2path05llmpart2contenttypedirectoryname06paralleltrainingpath06paralleltrainingcontenttypedirectoryname08advancedarchitecturesmethodspath08advancedarchitecturesmethodscontenttypedirectorynamebonusmaterialpathbonusmaterialcontenttypedirectorynamegitattributespathgitattributescontenttypefilenamegitconfigpathgitconfigcontenttypefilenamegitignorepathgitignorecontenttypefilenamereadmemdpathreadmemdcontenttypefiletotalcount13filetreeprocessingtime4977568folderstofetchrepoid754304606defaultbranchmainnameaisciencetrainingseriesownerloginhjiang13currentusercanpushfalseisforktrueisemptyfalsecreatedat20240207t194143000zowneravatarhttpsavatarsgithubusercontentcomu43047519v4publictrueprivatefalseisorgownedfalsesymbolsexpandedfalsetreeexpandedtruerefinfonamemainlistcachekeyv01707334909286934caneditfalsereftypebranchcurrentoid063b58e131dad402e1dbff364ff940432b72468apath04introtollmslifeonthemississippitxtcurrentusernullblobrawlines\\ufeffthe', 1)\n",
            "('project', 65)\n",
            "('gutenberg', 20)\n",
            "('ebook', 11)\n",
            "('of', 3993)\n",
            "('life', 73)\n",
            "('on', 829)\n",
            "('the', 7782)\n",
            "('mississippir', 1)\n",
            "('rthis', 1)\n"
          ]
        }
      ],
      "source": [
        "wdict = {}\n",
        "frequence = {}\n",
        "\n",
        "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "\n",
        "with open('Life_On_The_Mississippi.txt', 'r') as L:\n",
        "    line = L.readline()\n",
        "    nlines = 1\n",
        "    while line:\n",
        "      #Hailong Jiang 03/10/2024\n",
        "      #To eliminate punctuation\n",
        "      line = line.translate(table)\n",
        "      #To lower case\n",
        "      line = line.lower()\n",
        "\n",
        "      words = line.split()\n",
        "      for word in words:\n",
        "          if wdict.get(word) is not None:\n",
        "              wdict[word] += 1\n",
        "          else:\n",
        "              wdict[word] = 1\n",
        "      # To count the frequence\n",
        "      for word in words:\n",
        "          if frequence.get(word) is not None:\n",
        "              frequence[word] += 1\n",
        "          else:\n",
        "              frequence[word] = 1\n",
        "      line = L.readline()\n",
        "      nlines += 1\n",
        "\n",
        "nitem = 0 ; maxitems = 10\n",
        "for item in wdict.items():\n",
        "    nitem += 1\n",
        "    print(item)\n",
        "    if nitem == maxitems: break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topK = 10\n",
        "print(f\"The top {topK} frequnt words are: \")\n",
        "\n",
        "frequence_sort = sorted(frequence.items(), key = lambda kv: (kv[1], kv[0]), reverse=True)\n",
        "fitem = 0\n",
        "for item in frequence_sort:\n",
        "    fitem += 1\n",
        "    print(item)\n",
        "    if fitem == topK: break"
      ],
      "metadata": {
        "id": "_JhX4Q3d7cPa",
        "outputId": "590bfd7b-f9b8-4d3d-d94f-6db4338ce798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 10 frequnt words are: \n",
            "('the', 7782)\n",
            "('and', 5019)\n",
            "('of', 3993)\n",
            "('a', 3523)\n",
            "('to', 3185)\n",
            "('in', 2240)\n",
            "('it', 1929)\n",
            "('was', 1827)\n",
            "('i', 1805)\n",
            "('that', 1475)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = sum(frequence.values())\n",
        "currentFrequency = 0\n",
        "count = 0\n",
        "for item in frequence_sort:\n",
        "    currentFrequency += item[1]\n",
        "    count += 1\n",
        "    if currentFrequency/total > 0.9:\n",
        "      print(f\"The top {count} words make up the 90% frequence.\")\n",
        "      break"
      ],
      "metadata": {
        "id": "o_Cp_mnz7eYW",
        "outputId": "e3aedfa8-126c-4648-a69d-c5f637625b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-82a5f3b51a1e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcurrentFrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrequence_sort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcurrentFrequency\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch.venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}